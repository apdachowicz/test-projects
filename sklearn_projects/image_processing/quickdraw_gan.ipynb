{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import clear_output\n",
    "import pandas as pd\n",
    "from skimage.io import imread\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "from sklearn.decomposition import IncrementalPCA\n",
    "from sklearn_projects.image_processing.quickdraw.imagebuilder \\\n",
    "    import QuickDrawImageBuilder as ImageBuilder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tensorflow import keras\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing import image_dataset_from_directory\n",
    "from tensorflow.keras import datasets, layers, models, Input, optimizers\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.layers import Conv2D, Conv2DTranspose\n",
    "from tensorflow.keras.layers import LeakyReLU, ReLU\n",
    "from tensorflow.keras.layers import MaxPooling2D, AveragePooling2D\n",
    "from tensorflow.keras.layers import Activation\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras.layers import Reshape\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers.experimental.preprocessing import Rescaling\n",
    "from tensorflow.keras.layers import concatenate\n",
    "from tensorflow.keras.utils import plot_model\n",
    "\n",
    "\n",
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# QuickDraw dataset GAN.\n",
    "\n",
    "Let's try creating a generative adversarial network (GAN) for the QuickDraw dataset.\n",
    "If successful, this will give us a model capable of \"hallucinating\" drawings based on the\n",
    "training data available in the QuickDraw datasets.\n",
    "\n",
    "Note this assumes you already have directories containing the .png image files\n",
    "generated in `sklearn_projects/image_processing/quickdraw_analysis.ipynb`."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# pull in data and visualize\n",
    "###############\n",
    "data_names = ['cat']\n",
    "path_to_data = 'D:/Personal/code_projects/test-projects/datasets/quickdraw/quickdraw_simplified/'\n",
    "###############\n",
    "\n",
    "for data_name in data_names:\n",
    "\n",
    "    # data location\n",
    "    image_path = path_to_data + 'output_images/' + data_name + '/images/'\n",
    "\n",
    "    # meta file\n",
    "    meta_df = pd.read_csv(path_to_data + 'output_images/' + data_name + '/meta/meta.csv')\n",
    "    # print(meta_df['recognized'].value_counts())\n",
    "\n",
    "    # get image indices of recognized images:\n",
    "    image_indices = meta_df[meta_df['recognized']==True]['sample_id'].values.tolist()\n",
    "\n",
    "    plt.figure(figsize=(12,12))\n",
    "    for plot_index, sample_id in enumerate(image_indices[:16]):\n",
    "        sample = imread(image_path+'sample{}.png'.format(sample_id),\n",
    "                        as_gray=True)\n",
    "        plt.subplot(4,4,plot_index+1)\n",
    "        plt.imshow(sample,\n",
    "                   cmap='gray')\n",
    "        plt.xticks([])\n",
    "        plt.yticks([])\n",
    "        plt.colorbar()\n",
    "        num_strokes = meta_df[meta_df['sample_id'] == sample_id]['num_strokes'].values.tolist()[0]\n",
    "        plt.title('Sample: {}, Strokes: {}'.format(sample_id, num_strokes))\n",
    "    plt.suptitle('Item: {}'.format(data_name),\n",
    "                 fontsize=18)\n",
    "    plt.show();"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# define input dataset\n",
    "################\n",
    "image_class = 'cat'\n",
    "path_to_class_images = 'D:/Personal/code_projects/test-projects/datasets/quickdraw/quickdraw_simplified/output_images/'\n",
    "seed = 18210\n",
    "val_split = 0.2\n",
    "batch_size = 64\n",
    "image_size = (64, 64)  # downsampling from original (256, 256) to speed training\n",
    "################\n",
    "\n",
    "# TODO: for gan, don't need a validation set... just put all in \"training.\"\n",
    "\n",
    "train_dataset = image_dataset_from_directory(directory=path_to_class_images + '{}/'.format(image_class),\n",
    "                                             label_mode=None,\n",
    "                                             seed=seed,\n",
    "                                             validation_split=val_split,\n",
    "                                             batch_size=batch_size,\n",
    "                                             image_size=image_size,\n",
    "                                             color_mode='grayscale',\n",
    "                                             interpolation='area',\n",
    "                                             subset='training')\n",
    "\n",
    "# ensure the max. pixel value in all input images is in [-1,1]\n",
    "train_dataset = train_dataset.map(lambda x:\n",
    "                                  tf.math.add(\n",
    "                                      tf.math.scalar_mul(1./127.5, x),\n",
    "                                      tf.math.scalar_mul(-1, tf.ones(shape=(image_size[0],image_size[1],1)))\n",
    "                                  ))\n",
    "\n",
    "val_dataset = image_dataset_from_directory(directory=path_to_class_images + '{}/'.format(image_class),\n",
    "                                           label_mode=None,\n",
    "                                           seed=seed,\n",
    "                                           validation_split=val_split,\n",
    "                                           batch_size=batch_size,\n",
    "                                           image_size=image_size,\n",
    "                                           color_mode='grayscale',\n",
    "                                           interpolation='area',\n",
    "                                           subset='validation')\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# viz. training data samples\n",
    "dataset_names = ['Training', 'Validation']\n",
    "for dataset_index, dataset in enumerate([train_dataset, val_dataset]):\n",
    "    plt.figure(figsize = (16,8))\n",
    "    for batch in dataset.take(1):\n",
    "        for i in range(8):\n",
    "            image = batch[i,:,:,0]\n",
    "            plt.subplot(2, 4, i + 1)\n",
    "            plt.imshow(image,\n",
    "                       cmap='gray')\n",
    "            plt.title('{} Set, Sample {}'.format(dataset_names[dataset_index],\n",
    "                                                str(i+1)))\n",
    "            plt.colorbar()\n",
    "            plt.xticks([])\n",
    "            plt.yticks([])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "######################\n",
    "# discriminator inputs\n",
    "dropout_prob = 0.5\n",
    "padding = 'same'\n",
    "leakyrelu_alpha = -1./5.5\n",
    "######################\n",
    "\n",
    "# define the discriminator network\n",
    "def get_discriminator(image_input_shape=(256, 256, 1),\n",
    "                      dropout_prob = 0.4,\n",
    "                      padding = 'same',\n",
    "                      leakyrelu_alpha = -1./5.5):\n",
    "    \"\"\"\n",
    "    Build the discriminator model.\n",
    "\n",
    "    This model takes as input an image, and outputs whether this image is\n",
    "    a real or fake example from the target dataset.\n",
    "\n",
    "    :param image_input_shape: the shape of the input image.\n",
    "    :param dropout_prob: dropout probability. If 0, dropout layers will not be added.\n",
    "    :param padding: type of padding for Conv2D and MaxPooling2D layers. Either 'same' or 'valid',\n",
    "     defaults to 'same'.\n",
    "    :return: model: the discriminator model.\n",
    "    \"\"\"\n",
    "\n",
    "    # input\n",
    "    image_input = Input(shape=image_input_shape)\n",
    "    # x = Rescaling(scale=1./127.5, offset=1.)(image_input)  # rescale to [-1,1]\n",
    "\n",
    "    # model\n",
    "    #########\n",
    "    # 1st conv. layer\n",
    "    #########\n",
    "    x = Conv2D(filters=64,\n",
    "               kernel_size=(5, 5),\n",
    "               strides=(1, 1),\n",
    "               padding=padding,\n",
    "               kernel_initializer='glorot_normal')(image_input)\n",
    "    x = AveragePooling2D(pool_size=(2,2),\n",
    "                         padding='same')(x)\n",
    "    x = LeakyReLU(alpha=leakyrelu_alpha)(x)\n",
    "    if dropout_prob > 0:\n",
    "        x = Dropout(dropout_prob)(x)\n",
    "    #########\n",
    "    # 2nd conv. layer\n",
    "    #########\n",
    "    x = Conv2D(filters=32,\n",
    "               kernel_size=(3, 3),\n",
    "               strides=(1, 1),\n",
    "               padding=padding,\n",
    "               kernel_initializer='glorot_normal')(x)\n",
    "    x = AveragePooling2D(pool_size=(2,2),\n",
    "                         padding='same')(x)\n",
    "    x = LeakyReLU(alpha=leakyrelu_alpha)(x)\n",
    "    if dropout_prob > 0:\n",
    "        x = Dropout(dropout_prob)(x)\n",
    "    #########\n",
    "    # 3rd conv. layer\n",
    "    #########\n",
    "    x = Conv2D(filters=16,\n",
    "               kernel_size=(3, 3),\n",
    "               strides=(1, 1),\n",
    "               padding=padding,\n",
    "               kernel_initializer='glorot_normal')(x)\n",
    "    x = AveragePooling2D(pool_size=(2,2),\n",
    "                         padding='same')(x)\n",
    "    x = LeakyReLU(alpha=leakyrelu_alpha)(x)\n",
    "    if dropout_prob > 0:\n",
    "        x = Dropout(dropout_prob)(x)\n",
    "    #########\n",
    "    # output\n",
    "    #########\n",
    "    x = Flatten()(x)\n",
    "    x = Dense(units=1,\n",
    "              activation='sigmoid')(x)\n",
    "    discriminator = Model(inputs=image_input,\n",
    "                          outputs=x,\n",
    "                          name='discriminator')\n",
    "\n",
    "    return discriminator\n",
    "\n",
    "discriminator = get_discriminator(image_input_shape=(image_size[0], image_size[1], 1),\n",
    "                                  dropout_prob=dropout_prob,\n",
    "                                  padding=padding,\n",
    "                                  leakyrelu_alpha=leakyrelu_alpha)\n",
    "discriminator.summary()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "######################\n",
    "# generator inputs\n",
    "gen_input_shape = (120,)\n",
    "padding = 'same'\n",
    "batchnorm_momentum = 0.8\n",
    "initial_depth = 50\n",
    "initial_width = 8\n",
    "leakyrelu_alpha = 0.3\n",
    "dropout_prob = 0.5\n",
    "######################\n",
    "\n",
    "# and build the generator model\n",
    "\n",
    "def get_generator(gen_input_shape=(100,),\n",
    "                  padding='same',\n",
    "                  batchnorm_momentum=0.8,\n",
    "                  initial_depth=256,\n",
    "                  initial_width=11,\n",
    "                  leakyrelu_alpha=-1./5.5,\n",
    "                  dropout_prob=0.4):\n",
    "\n",
    "    # input\n",
    "    gen_input = Input(shape=gen_input_shape)\n",
    "\n",
    "    # model\n",
    "    ###########\n",
    "    # build and shape tensor for inverse convolution\n",
    "    ###########\n",
    "    y = Dense(initial_depth*initial_width*initial_width)(gen_input)\n",
    "    y = BatchNormalization(momentum=batchnorm_momentum)(y)\n",
    "    y = LeakyReLU(alpha=leakyrelu_alpha)(y)\n",
    "    y = Reshape((initial_width, initial_width, initial_depth))(y)\n",
    "    if dropout_prob > 0:\n",
    "        y = Dropout(dropout_prob)(y)\n",
    "    ###########\n",
    "    # 1st Conv2dTranspose\n",
    "    ###########\n",
    "    # y = Conv2DTranspose(filters=int(initial_depth/2),\n",
    "    #                     kernel_size=(3, 3),\n",
    "    #                     strides=(2,2),\n",
    "    #                     padding=padding,\n",
    "    #                     kernel_initializer='glorot_normal')(y)\n",
    "    # y = BatchNormalization(momentum=batchnorm_momentum)(y)\n",
    "    # y = LeakyReLU(alpha=leakyrelu_alpha)(y)\n",
    "    # if dropout_prob > 0:\n",
    "    #     y = Dropout(dropout_prob)(y)\n",
    "    ###########\n",
    "    # 2nd Conv2dTranspose\n",
    "    ###########\n",
    "    y = Conv2DTranspose(filters=int(initial_depth/3),\n",
    "                        kernel_size=(3, 3),\n",
    "                        strides=(2, 2),\n",
    "                        padding=padding,\n",
    "                        kernel_initializer='glorot_normal')(y)\n",
    "    y = BatchNormalization(momentum=batchnorm_momentum)(y)\n",
    "    y = LeakyReLU(alpha=leakyrelu_alpha)(y)\n",
    "    if dropout_prob > 0:\n",
    "        y = Dropout(dropout_prob)(y)\n",
    "    ###########\n",
    "    # 3rd Conv2dTranspose\n",
    "    ###########\n",
    "    y = Conv2DTranspose(filters=int(initial_depth/6),\n",
    "                        kernel_size=(5, 5),\n",
    "                        strides=(2, 2),\n",
    "                        padding=padding,\n",
    "                        kernel_initializer='glorot_normal')(y)\n",
    "    y = BatchNormalization(momentum=batchnorm_momentum)(y)\n",
    "    y = LeakyReLU(alpha=leakyrelu_alpha)(y)\n",
    "    if dropout_prob > 0:\n",
    "        y = Dropout(dropout_prob)(y)\n",
    "    ###########\n",
    "    # 4th Conv2dTranspose\n",
    "    ###########\n",
    "    # y = Conv2DTranspose(filters=int(initial_depth/16),\n",
    "    #                     kernel_size=(5, 5),\n",
    "    #                     strides=(2, 2),\n",
    "    #                     padding=padding,\n",
    "    #                     kernel_initializer='glorot_normal')(y)\n",
    "    # y = BatchNormalization(momentum=batchnorm_momentum)(y)\n",
    "    # y = LeakyReLU(alpha=leakyrelu_alpha)(y)\n",
    "    # if dropout_prob > 0:\n",
    "    #     y = Dropout(dropout_prob)(y)\n",
    "    ##########\n",
    "    # output\n",
    "    ##########\n",
    "    y = Conv2DTranspose(filters = 1,\n",
    "                        kernel_size=(5, 5),\n",
    "                        strides=(2, 2),\n",
    "                        padding=padding,\n",
    "                        kernel_initializer='glorot_normal',\n",
    "                        activation='tanh')(y)\n",
    "    generator = Model(inputs=gen_input,\n",
    "                      outputs=y,\n",
    "                      name='generator')\n",
    "\n",
    "    return generator\n",
    "\n",
    "generator = get_generator(gen_input_shape=gen_input_shape,\n",
    "                          padding=padding,\n",
    "                          batchnorm_momentum=batchnorm_momentum,\n",
    "                          initial_depth=initial_depth,\n",
    "                          initial_width=initial_width,\n",
    "                          leakyrelu_alpha=leakyrelu_alpha,\n",
    "                          dropout_prob=dropout_prob)\n",
    "\n",
    "generator.summary()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# define adversarial model\n",
    "def get_adversarial(generator,\n",
    "                    discriminator):\n",
    "    adversarial = Sequential(name='adversarial')\n",
    "    adversarial.add(generator)\n",
    "\n",
    "    # only train generator layers\n",
    "    for layer in discriminator.layers:\n",
    "        layer.trainable = False\n",
    "    adversarial.add(discriminator)\n",
    "\n",
    "    # compile\n",
    "    optimizer = keras.optimizers.Adam(learning_rate=0.0005)\n",
    "    adversarial.compile(loss='mean_squared_error',\n",
    "                        optimizer=optimizer,\n",
    "                        metrics=['mean_squared_error', 'mean_absolute_error'])\n",
    "\n",
    "    return adversarial\n",
    "\n",
    "# compile discriminator before adversarial, so weights can be frozen there\n",
    "dis_optimizer = keras.optimizers.Adam(learning_rate=0.000005)\n",
    "discriminator.compile(loss='mean_squared_error',\n",
    "                      optimizer=dis_optimizer,\n",
    "                      metrics=['mean_squared_error', 'mean_absolute_error'])\n",
    "\n",
    "adversarial = get_adversarial(generator,\n",
    "                              discriminator)\n",
    "\n",
    "\n",
    "\n",
    "adversarial.summary()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# plot_model(adversarial)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Training the GAN.\n",
    "\n",
    "Stil experimental. Consider referencing the [work](https://github.com/soumith/ganhacks) of\n",
    "S. Chintala, E. Denton, M. Arjovsky, and M. Mathieu. (I still haven't updated my naive model\n",
    "with most of their recommendations... working on it!)\n",
    "\n",
    "Tips from the reference that have been implemented:\n",
    "\n",
    "1. **Normalize inputs** in [-1, 1], and use **tanh** as output activation for the generator.\n",
    "2. Use **spherical noise**, that is noise drawn from Gaussian centered at 0 rather than a uniform\n",
    " distribution.\n",
    "3. Use **noisy labels**, $y_{true} \\in [0.085, 1.15]$ and $y_{gen} \\in [-0.15, 0.15]$.\n",
    "4. Use **Average Pooling** for downsampling to avoid sparse gradients (and LeakyReLU activations).\n",
    "5. Use **Adam** optimizer for the generator, and use **SGD** for the discriminator. (Note: not sure why\n",
    " SGD is recommended for the discrminator... generally Adam has a better reputation?)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# train the GAN!\n",
    "# TODO: implement training\n",
    "\n",
    "##############\n",
    "# inputs\n",
    "train_steps = 100\n",
    "batch_lim = 200\n",
    "##############\n",
    "\n",
    "adv_losses = []\n",
    "dis_losses = []\n",
    "epoch = 0\n",
    "\n",
    "# visualization\n",
    "viz_noise = np.random.normal(0., 1., size=[9,\n",
    "                                           gen_input_shape[0]])\n",
    "\n",
    "for step in range(train_steps):\n",
    "    epoch += 1\n",
    "    batch_count = 0\n",
    "    for batch in train_dataset.batch(batch_size=1,\n",
    "                                     drop_remainder=True):\n",
    "        batch_count += 1\n",
    "        if batch_count > batch_lim:\n",
    "            break\n",
    "        noise = np.random.normal(0., 1., size=[batch_size,\n",
    "                                               gen_input_shape[0]])\n",
    "        true_images = batch[0,:,:,:,:]\n",
    "\n",
    "        # gen. fake images\n",
    "        fake_images = generator.predict(noise)\n",
    "\n",
    "        # build training data\n",
    "        x = np.concatenate((true_images, fake_images))\n",
    "        # y = np.ones([2*batch_size, 1])\n",
    "        y = np.random.uniform(0.85,1.15,size=[2*batch_size, 1])  # noisy labels, 1 true, 0 fake\n",
    "        y[batch_size:, :] = np.random.uniform(-0.15,0.15, size=[batch_size, 1]) # 1 true, 0 fake\n",
    "        if batch_count == 1:\n",
    "            print(y)\n",
    "\n",
    "        # train discriminator\n",
    "        discrim_loss = discriminator.train_on_batch(x, y)\n",
    "        # dis_losses += [discrim_loss]\n",
    "\n",
    "        # get adversarial data (generated only)\n",
    "        noise = np.random.normal(0., 1., size=[batch_size,\n",
    "                                               gen_input_shape[0]])\n",
    "        # y = np.ones([batch_size, 1])\n",
    "        y = np.random.uniform(0.85,1.15, size=[batch_size, 1])  # noisy labels, 1 = true (trying to fool discrim)\n",
    "        if batch_count == 1:\n",
    "            print(y)\n",
    "\n",
    "        # train adversarial (generator and discriminator)\n",
    "        adv_loss = adversarial.train_on_batch(noise, y)\n",
    "        # adv_losses += [adv_loss]\n",
    "        # if step%5 == 0:\n",
    "        if batch_count%10 == 0:\n",
    "            clear_output(wait=True)\n",
    "            print('Epoch: {}, Batch: {}'.format(step+1, batch_count+1))\n",
    "            print('    Adv. Loss: {:.6f}, Mean. Abs. Err: {:.6f}.'.format(adv_loss[0], adv_loss[2]))\n",
    "            print('    Dis. Loss: {:.6f}, Mean. Abs. Err: {:.6f}.'.format(discrim_loss[0], discrim_loss[2]))\n",
    "            print('        Discrim. weight check: SHOULD CHANGE: {:.6f}'.format(discriminator.layers[1].get_weights()[0][0,0,0,0]))\n",
    "            print('        Discrim. weight check: SHOULD MATCH:  {:.6f}'.format(np.array(adversarial.layers[1].get_weights()[0])[0,0,0,0]))\n",
    "            plt.figure(10,\n",
    "                       figsize=(12, 12))\n",
    "            viz_images = generator.predict(viz_noise)\n",
    "            for viz_image in range(viz_images.shape[0]):\n",
    "                plt.subplot(3, 3, viz_image + 1)\n",
    "                plt.imshow(viz_images[viz_image,:,:,0])\n",
    "                plt.xticks([])\n",
    "                plt.yticks([])\n",
    "                plt.colorbar()\n",
    "            plt.suptitle('Generated Images,\\nEpoch {} Batch {}'.format(epoch, batch_count),\n",
    "                         fontsize=24)\n",
    "            plt.show()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "adv_loss"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# noise = np.random.uniform(-1.0, 1.0, size=[9,\n",
    "#                                            gen_input_shape[0]])\n",
    "# gen_images = generator.predict(noise)\n",
    "# gen_images.shape\n",
    "# for layer in discriminator.layers[3:]:\n",
    "#     try:\n",
    "#         print(layer.get_weights()[0].shape)\n",
    "#     except IndexError: pass\n",
    "# print()\n",
    "# for layer in adversarial.layers:\n",
    "#     print(layer.get_weights()[0].shape)\n",
    "#\n",
    "# print(np.array(adversarial.layers[1].get_weights()[0])[0,0,0,0])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Hard lessons:\n",
    "\n",
    "1. The first inverse convolutional layer of the generator should have channels of sufficient width (>8 pixels),\n",
    " or the results won't have enough \"expressiveness.\" That is, outputs will have a tiled/quilted structure."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "pycharm-46783112",
   "language": "python",
   "display_name": "PyCharm (test-projects)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}